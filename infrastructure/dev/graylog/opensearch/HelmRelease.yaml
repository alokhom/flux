apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: opensearch
  namespace: graylog
spec:
  interval: 30m
  chart:
    spec:
      chart: opensearch
      version: "2.11.4"
      sourceRef:
        kind: HelmRepository
        name: opensearch
        namespace: graylog
      interval: 5m
  values:
    clusterName: "graylog"
    nodeGroup: "master"

    # If discovery.type in the opensearch configuration is set to "single-node",
    # this should be set to "true"
    # If "true", replicas will be forced to 1
    singleNode: true

    # The service that non master groups will try to connect to when joining the cluster
    # This should be set to clusterName + "-" + nodeGroup for your master group
    masterService: "graylog-master"

    # OpenSearch roles that will be applied to this nodeGroup
    # These will be set as environment variable "node.roles". E.g. node.roles=master,ingest,data,remote_cluster_client
    roles:
      - master
      - ingest
      - data
      - remote_cluster_client

    replicas: 3

    # if not set, falls back to parsing .Values.imageTag, then .Chart.appVersion.
    majorVersion: ""

    global:
      # Set if you want to change the default docker registry, e.g. a private one.
      dockerRegistry: ""

    # Allows you to add any config files in {{ .Values.opensearchHome }}/config
    opensearchHome: /usr/share/opensearch
    # such as opensearch.yml and log4j2.properties
    config:
      # Values must be YAML literal style scalar / YAML multiline string.
      # <filename>: |
      #   <formatted-value(s)>
      log4j2.properties: |
        status = error
        appender.console.type = Console
        appender.console.name = console
        appender.console.layout.type = PatternLayout
        appender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %m%n
        rootLogger.level = info
        rootLogger.appenderRef.console.ref = console
      opensearch.yml: |
        cluster.name: graylog

        # Bind to all interfaces because we don't know what IP address Docker will assign to us.
        network.host: 0.0.0.0

        # Setting network.host to a non-loopback address enables the annoying bootstrap checks. "Single-node" mode disables them again.
        # Implicitly done if ".singleNode" is set to "true".
        discovery.type: single-node
        bootstrap.memory_lock: false
        action.auto_create_index: false
        ############## OpenSearch Security configuration ###############

        ###########################################################
        # Add the following settings to your standard opensearch.yml
        # alongside with the OpenSearch Security TLS settings.
        # Settings must always be the same on all nodes in the cluster.

        ############## Common configuration settings ##############

        # Specify a list of DNs which denote the other nodes in the cluster.
        # This settings support wildcards and regular expressions
        # The list of DNs are also read from security index **in addition** to the yml configuration if
        # plugins.security.nodes_dn_dynamic_config_enabled is true.
        # NOTE: This setting only has effect if 'plugins.security.cert.intercluster_request_evaluator_class' is not set.
        plugins.security.nodes_dn:
          - "CN=*.example.com, OU=SSL, O=Test, L=Test, C=DE"
          - "CN=node.other.com, OU=SSL, O=Test, L=Test, C=DE"

        # The nodes_dn_dynamic_config_enabled settings is geared towards cross_cluster usecases where there is a need to
        # manage the whitelisted nodes_dn without having to restart the nodes everytime a new cross_cluster remote is configured
        # Setting nodes_dn_dynamic_config_enabled to true enables **super-admin callable** /_opendistro/_security/api/nodesdn APIs
        # which provide means to update/retrieve nodesdn dynamically.
        #
        # NOTE: The overall whitelisted nodes_dn evaluated comes from both the plugins.security.nodes_dn and the ones stored
        # in security index.
        # (default: false)
        # NOTE2: This setting only has effect if 'plugins.security.cert.intercluster_request_evaluator_class' is not set.
        plugins.security.nodes_dn_dynamic_config_enabled: false

        # Defines the DNs (distinguished names) of certificates
        # to which admin privileges should be assigned (mandatory)
        plugins.security.authcz.admin_dn:
          - "CN=kirk,OU=client,O=client,l=tEst, C=De"

        # Define how backend roles should be mapped to Security roles
        # MAPPING_ONLY - mappings must be configured explicitely in roles_mapping.yml (default)
        # BACKENDROLES_ONLY - backend roles are mapped to Security roles directly. Settings in roles_mapping.yml have no effect.
        # BOTH - backend roles are mapped to Security roles mapped directly and via roles_mapping.yml in addition
        plugins.security.roles_mapping_resolution: MAPPING_ONLY

        ############## REST Management API configuration settings ##############
        # Enable or disable role based access to the REST management API
        # Default is that no role is allowed to access the REST management API.
        #plugins.security.restapi.roles_enabled: ["all_access","xyz_role"]

        # Disable particular endpoints and their HTTP methods for roles. 
        # By default all endpoints/methods are allowed.
        #plugins.security.restapi.endpoints_disabled.<role>.<endpoint>: <array of http methods>
        # Example:
        #plugins.security.restapi.endpoints_disabled.all_access.ACTIONGROUPS: ["PUT","POST","DELETE"]
        #plugins.security.restapi.endpoints_disabled.xyz_role.LICENSE: ["DELETE"]

        # The following endpoints exist:
        # ACTIONGROUPS
        # CACHE
        # CONFIG
        # ROLES
        # ROLESMAPPING
        # INTERNALUSERS
        # SYSTEMINFO
        # PERMISSIONSINFO

        ############## Auditlog configuration settings ##############
        # General settings

        # Enable/disable rest request logging (default: true)
        #plugins.security.audit.enable_rest: true
        # Enable/disable transport request logging (default: false)
        #plugins.security.audit.enable_transport: false
        # Enable/disable bulk request logging (default: false)
        # If enabled all subrequests in bulk requests will be logged too
        #plugins.security.audit.resolve_bulk_requests: false
        # Disable some categories
        #plugins.security.audit.config.disabled_categories: ["AUTHENTICATED","GRANTED_PRIVILEGES"]
        # Disable some requests (wildcard or regex of actions or rest request paths)
        #plugins.security.audit.ignore_requests: ["indices:data/read/*","*_bulk"]
        # Tune threadpool size, default is 10
        #plugins.security.audit.threadpool.size: 10
        # Tune threadpool max size queue length, default is 100000
        #plugins.security.audit.threadpool.max_queue_len: 100000

        # Ignore users, e.g. do not log audit requests from that users (default: no ignored users)
        #plugins.security.audit.ignore_users: ['kibanaserver','some*user','/also.*regex possible/']"

        # Destination of the auditlog events
        plugins.security.audit.type: internal_opensearch
        #plugins.security.audit.type: external_opensearch
        #plugins.security.audit.type: debug
        #plugins.security.audit.type: webhook

        # external_opensearch settings
        #plugins.security.audit.config.http_endpoints: ['localhost:9200','localhost:9201','localhost:9202']"
        # Auditlog index can be a static one or one with a date pattern (default is 'auditlog6')
        #plugins.security.audit.config.index: auditlog6 # make sure you secure this index properly
        #plugins.security.audit.config.index: "'auditlog6-'YYYY.MM.dd" #rotates index daily - make sure you secure this index properly
        #plugins.security.audit.config.type: auditlog
        #plugins.security.audit.config.username: auditloguser
        #plugins.security.audit.config.password: auditlogpassword
        #plugins.security.audit.config.enable_ssl: false
        #plugins.security.audit.config.verify_hostnames: false
        #plugins.security.audit.config.enable_ssl_client_auth: false
        #plugins.security.audit.config.cert_alias: mycert
        #plugins.security.audit.config.pemkey_filepath: key.pem
        #plugins.security.audit.config.pemkey_content: <...pem base 64 content>
        #plugins.security.audit.config.pemkey_password: secret
        #plugins.security.audit.config.pemcert_filepath: cert.pem
        #plugins.security.audit.config.pemcert_content: <...pem base 64 content>
        #plugins.security.audit.config.pemtrustedcas_filepath: ca.pem
        #plugins.security.audit.config.pemtrustedcas_content: <...pem base 64 content>

        # webhook settings
        #plugins.security.audit.config.webhook.url: "http://mywebhook/endpoint"
        # One of URL_PARAMETER_GET,URL_PARAMETER_POST,TEXT,JSON,SLACK
        #plugins.security.audit.config.webhook.format: JSON
        #plugins.security.audit.config.webhook.ssl.verify: false
        #plugins.security.audit.config.webhook.ssl.pemtrustedcas_filepath: ca.pem
        #plugins.security.audit.config.webhook.ssl.pemtrustedcas_content: <...pem base 64 content>

        # log4j settings
        #plugins.security.audit.config.log4j.logger_name: auditlogger
        #plugins.security.audit.config.log4j.level: INFO

        ############## Kerberos configuration settings ##############
        # If Kerberos authentication should be used you have to configure:

        # The Path to the krb5.conf file
        # Can be absolute or relative to the OpenSearch config directory
        #plugins.security.kerberos.krb5_filepath: '/etc/krb5.conf'
                    
        # The Path to the keytab where the acceptor_principal credentials are stored.           
        # Must be relative to the OpenSearch config directory
        #plugins.security.kerberos.acceptor_keytab_filepath: 'eskeytab.tab'

        # Acceptor (Server) Principal name, must be present in acceptor_keytab_path file
        #plugins.security.kerberos.acceptor_principal: 'HTTP/localhost'

        ############## Advanced configuration settings ##############
        # Enable transport layer impersonation
        # Allow DNs (distinguished names) to impersonate as other users
        #plugins.security.authcz.impersonation_dn:
        #  "CN=spock,OU=client,O=client,L=Test,C=DE":
        #    - worf
        #  "cn=webuser,ou=IT,ou=IT,dc=company,dc=com":
        #    - user2
        #    - user1

        # Enable rest layer impersonation
        # Allow users to impersonate as other users
        #plugins.security.authcz.rest_impersonation_user:
        #  "picard":
        #    - worf
        #  "john":
        #    - steve
        #    - martin

        # If this is set to true OpenSearch Security will automatically initialize the configuration index
        # with the files in the config directory if the index does not exist.
        # WARNING: This will use well-known default passwords.
        #          Use only in a private network/environment.
        #plugins.security.allow_default_init_securityindex: false

        # If this is set to true then allow to startup with demo certificates.
        # These are certificates issued by floragunn GmbH for demo purposes.
        # WARNING: This certificates are well known and therefore unsafe
        #          Use only in a private network/environment.
        #plugins.security.allow_unsafe_democertificates: false



        # Password strength rules for password complexity. 
        # If you want to set up password strength rules for internal users, you can use the below settings for it. 
        # Password validation rules can be configured through regex. In the below regex example, a user must need 
        # a password with minimum 8 characters length and must include minimum one uppercase, one lower case, one digit, and one special character. 
        # And a custom error message can be configured, in case if a password is not created according to the password strength rule.   
        # plugins.security.restapi.password_validation_regex: '(?=.*[A-Z])(?=.*[^a-zA-Z\d])(?=.*[0-9])(?=.*[a-z]).{8,}'
        # plugins.security.restapi.password_validation_error_message: "A password must be at least 8 characters long and contain at least one uppercase letter, one lowercase letter, one digit, and one special character."


        ############## Expert settings ##############
        # WARNING: Expert settings, do only use if you know what you are doing
        # If you set wrong values here this this could be a security risk
        # or make OpenSearch Security stop working

        # Name of the index where .opendistro_security stores its configuration.

        #plugins.security.config_index_name: .opendistro_security

        # This defines the OID of server node certificates
        #plugins.security.cert.oid: '1.2.3.4.5.5'

        # This specifies the implementation of org.opensearch.security.transport.InterClusterRequestEvaluator
        # that is used to determine inter-cluster request.
        # Instances of org.opensearch.security.transport.InterClusterRequestEvaluator must implement a single argument
        # constructor that takes an org.opensearch.common.settings.Settings
        #plugins.security.cert.intercluster_request_evaluator_class: org.opensearch.security.transport.DefaultInterClusterRequestEvaluator

        # By default, normal users can restore snapshots if they have the priviliges 'cluster:admin/snapshot/restore', 
        # 'indices:admin/create', and 'indices:data/write/index' for the indices to be restored.
        # To disable snapshot restore for normal users set 'plugins.security.enable_snapshot_restore_privilege: false'.
        # This makes it so that only snapshot restore requests signed by an admin TLS certificate are accepted.
        # A snapshot can only be restored when it does not contain global state and does not restore the '.opendistro_security' index
        # If 'plugins.security.check_snapshot_restore_write_privileges: false' is set then the additional indices checks are omitted.
        #plugins.security.enable_snapshot_restore_privilege: true
        #plugins.security.check_snapshot_restore_write_privileges: true

        # Authentication cache timeout in minutes (A value of 0 disables caching, default is 60)
        #plugins.security.cache.ttl_minutes: 60

        # Disable OpenSearch Security
        # WARNING: This can expose your configuration (including passwords) to the public.
        plugins.security.disabled: true


        # Protected indices are even more secure than normal indices. These indices require a role to access like any other index, but they require an additional role
        # to be visible, listed in the plugins.security.protected_indices.roles setting.
        # Enable protected indices
        # plugins.security.protected_indices.enabled: true
        # Specify a list of roles a user must be member of to touch any protected index.
        # plugins.security.protected_indices.roles: ['all_access']
        # Specify a list of indices to mark as protected. These indices will only be visible / mutable by members of the above setting, in addition to needing permission to the index via a normal role.
        # plugins.security.protected_indices.indices: []

        # System indices are similar to security index, except the contents are not encrypted.
        # Indices configured as system indices can be accessed by only super-admin and no role will provide access to these indices.
        # Enable system indices
        # plugins.security.system_indices.enabled: true
        # Specify a list of indices to mark as system. These indices will only be visible / mutable by members of the above setting, in addition to needing permission to the index via a normal role.
        # plugins.security.system_indices.indices: ['.opendistro-alerting-config', '.opendistro-ism-*', '.opendistro-reports-*', '.opensearch-notifications-*', '.opensearch-notebooks', '.opensearch-observability', '.opendistro-asynchronous-search-response*', '.replication-metadata-store']

      internal_users.yml: |
        # This is the internal user database
        # The hash value is a bcrypt hash and can be generated with plugin/tools/hash.sh

        _meta:
          type: "internalusers"
          config_version: 2

        # Define your internal users here
        new-user:
          hash: "$2y$12$dn2Jz5.RNvpVkDbxxYBz9uowz41jAefGnzNlIcmxRX2dAudS1bOIK"
          reserved: false
          hidden: false
          opendistro_security_roles:
          - "complex-role"
          backend_roles:
          - "kibanauser"
          - "readall"
          attributes:
            attribute1: "value1"
          static: false

        ## Demo users

        admin:
          hash: "$2y$12$rX7LSbCqTGf0f5f/DZTmielDZQvwUghnykx7Lk43zFkh7F9yx9klm"
          reserved: true
          backend_roles:
          - "admin"
          description: "Demo admin user"

        kibanaserver:
          hash: "$2y$12$1Yep1oNP5qvNWz2p3DiWcO2lKGAWT8lrCeiX0ajl4lnNi6Ai1cctW"
          reserved: true
          description: "Demo user for the OpenSearch Dashboards server"

        kibanaro:
          hash: "$2y$12$G4kR4boTHOpqb7DgXSjae.4D3/6/aJvHu6KIMWs21J3e/eKlLSZYW"
          reserved: false
          backend_roles:
          - "kibanauser"
          - "readall"
          attributes:
            attribute1: "value1"
            attribute2: "value2"
            attribute3: "value3"
          description: "Demo read-only user for OpenSearch dashboards"

        logstash:
          hash: "$2y$12$.aJaHHKFcCisW32VNlahOu5b8XKwJtrJdOoG8d6geZC6c0/qYBsCW"
          reserved: false
          backend_roles:
          - "logstash"
          description: "Demo logstash user"

        readall:
          hash: "$2y$12$5u49jLMzpq5OLTgYxVisrufZe3k68uqfipbDzgvIcnfdtkm3qfY.u"
          reserved: false
          backend_roles:
          - "readall"
          description: "Demo readall user"

        snapshotrestore:
          hash: "$2y$12$yU3NaTvOWoz2TRWVASLOfe/h0qUi/OYAExn4xMAzzgByMK0Cc2s4u"
          reserved: false
          backend_roles:
          - "snapshotrestore"
          description: "Demo snapshotrestore user"
      allowlist.yml: |
        _meta:
          type: "allowlist"
          config_version: 2

        # Description:
        # enabled - feature flag.
        # if enabled is false, all endpoints are accessible.
        # if enabled is true, all users except the SuperAdmin can only submit the allowed requests to the specified endpoints.
        # SuperAdmin can access all APIs.
        # SuperAdmin is defined by the SuperAdmin certificate, which is configured with the opensearch.yml setting plugins.security.authcz.admin_dn:
        # Refer to the example setting in opensearch.yml to learn more about configuring SuperAdmin.
        #
        # requests - map of allow listed endpoints and HTTP requests

        #this name must be config
        config:
          enabled: true
          requests:
            /_cluster/settings:
              - GET
              - PUT
            /_cat/nodes:
              - GET
            /sample-index1/_doc/1:
              - GET
            /sample-index2/_doc/1:
              - GET
      roles.yml: |
        complex-role:
          reserved: false
          hidden: false
          cluster_permissions:
          - "read"
          - "cluster:monitor/nodes/stats"
          - "cluster:monitor/task/get"
          index_permissions:
          - index_patterns:
            - "opensearch_dashboards_sample_data_*"
            dls: "{\"match\": {\"FlightDelay\": true}}"
            fls:
            - "~FlightNum"
            masked_fields:
            - "Carrier"
            allowed_actions:
            - "read"
          tenant_permissions:
          - tenant_patterns:
            - "analyst_*"
            allowed_actions:
            - "kibana_all_write"
          static: false
        _meta:
          type: "roles"
          config_version: 2
      roles_mapping.yml: |
        manage_snapshots:
          reserved: true
          hidden: false
          backend_roles:
          - "snapshotrestore"
          hosts: []
          users: []
          and_backend_roles: []
        logstash:
          reserved: false
          hidden: false
          backend_roles:
          - "logstash"
          hosts: []
          users: []
          and_backend_roles: []
        own_index:
          reserved: false
          hidden: false
          backend_roles: []
          hosts: []
          users:
          - "*"
          and_backend_roles: []
          description: "Allow full access to an index named like the username"
        kibana_user:
          reserved: false
          hidden: false
          backend_roles:
          - "kibanauser"
          hosts: []
          users: []
          and_backend_roles: []
          description: "Maps kibanauser to kibana_user"
        complex-role:
          reserved: false
          hidden: false
          backend_roles:
          - "ldap-analyst"
          hosts: []
          users:
          - "new-user"
          and_backend_roles: []
        _meta:
          type: "rolesmapping"
          config_version: 2
        all_access:
          reserved: true
          hidden: false
          backend_roles:
          - "admin"
          hosts: []
          users: []
          and_backend_roles: []
          description: "Maps admin to all_access"
        readall:
          reserved: true
          hidden: false
          backend_roles:
          - "readall"
          hosts: []
          users: []
          and_backend_roles: []
        kibana_server:
          reserved: true
          hidden: false
          backend_roles: []
          hosts: []
          users:
          - "kibanaserver"
          and_backend_roles: []
      action_groups.yml: |
        my-action-group:
          reserved: false
          hidden: false
          allowed_actions:
          - "indices:data/write/index*"
          - "indices:data/write/update*"
          - "indices:admin/mapping/put"
          - "indices:data/write/bulk*"
          - "read"
          - "write"
          static: false
        _meta:
          type: "actiongroups"
          config_version: 2
      tenants.yml: |
        _meta:
          type: "tenants"
          config_version: 2
        admin_tenant:
          reserved: false
          description: "Demo tenant for admin user"
      nodes_dn.yml: |
        _meta:
          type: "nodesdn"
          config_version: 2

        # Define nodesdn mapping name and corresponding values
        # cluster1:
        #   nodes_dn:
        #       - CN=*.example.com
      custom-opensearch.yml: |
        - http.host:0.0.0.0
        - http.port:9200
        - http.cors.allow-origin:"http://localhost"
        - http.cors.enabled:true
        - http.cors.allow-headers:X-Requested-With,X-Auth-Token,Content-Type,Content-Length,Authorization
        - http.cors.allow-credentials:true
      config.yaml: |
        ---

        # This is the main OpenSearch Security configuration file where authentication
        # and authorization is defined.
        #
        # You need to configure at least one authentication domain in the authc of this file.
        # An authentication domain is responsible for extracting the user credentials from
        # the request and for validating them against an authentication backend like Active Directory for example.
        #
        # If more than one authentication domain is configured the first one which succeeds wins.
        # If all authentication domains fail then the request is unauthenticated.
        # In this case an exception is thrown and/or the HTTP status is set to 401.
        #
        # After authentication authorization (authz) will be applied. There can be zero or more authorizers which collect
        # the roles from a given backend for the authenticated user.
        #
        # Both, authc and auth can be enabled/disabled separately for REST and TRANSPORT layer. Default is true for both.
        #        http_enabled: true
        #        transport_enabled: true
        #
        # For HTTP it is possible to allow anonymous authentication. If that is the case then the HTTP authenticators try to
        # find user credentials in the HTTP request. If credentials are found then the user gets regularly authenticated.
        # If none can be found the user will be authenticated as an "anonymous" user. This user has always the username "anonymous"
        # and one role named "anonymous_backendrole".
        # If you enable anonymous authentication all HTTP authenticators will not challenge.
        #
        #
        # Note: If you define more than one HTTP authenticators make sure to put non-challenging authenticators like "proxy" or "clientcert"
        # first and the challenging one last.
        # Because it's not possible to challenge a client with two different authentication methods (for example
        # Kerberos and Basic) only one can have the challenge flag set to true. You can cope with this situation
        # by using pre-authentication, e.g. sending a HTTP Basic authentication header in the request.
        #
        # Default value of the challenge flag is true.
        #
        #
        # HTTP
        #   basic (challenging)
        #   proxy (not challenging, needs xff)
        #   kerberos (challenging)
        #   clientcert (not challenging, needs https)
        #   jwt (not challenging)
        #   host (not challenging) #DEPRECATED, will be removed in a future version.
        #                          host based authentication is configurable in roles_mapping

        # Authc
        #   internal
        #   noop
        #   ldap

        # Authz
        #   ldap
        #   noop
        _meta:
          type: "config"
          config_version: 2

        config:
          dynamic:
            # Set filtered_alias_mode to 'disallow' to forbid more than 2 filtered aliases per index
            # Set filtered_alias_mode to 'warn' to allow more than 2 filtered aliases per index but warns about it (default)
            # Set filtered_alias_mode to 'nowarn' to allow more than 2 filtered aliases per index silently
            #filtered_alias_mode: warn
            #do_not_fail_on_forbidden: false
            #kibana:
            # Kibana multitenancy
            #multitenancy_enabled: true
            #private_tenant_enabled: true
            #default_tenant: ""
            #server_username: kibanaserver
            #index: '.kibana'
            http:
              anonymous_auth_enabled: false
              xff:
                enabled: true
                #internalProxies: '192\.168\.0\.10|192\.168\.0\.11' # regex pattern
                internalProxies: '.*' # trust all internal proxies, regex pattern
                remoteIpHeader:  'x-forwarded-for'
                ###### see https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html for regex help
                ###### more information about XFF https://en.wikipedia.org/wiki/X-Forwarded-For
                ###### and here https://tools.ietf.org/html/rfc7239
                ###### and https://tomcat.apache.org/tomcat-8.0-doc/config/valve.html#Remote_IP_Valve
            authc:
              kerberos_auth_domain:
                http_enabled: false
                transport_enabled: false
                order: 6
                http_authenticator:
                  type: kerberos
                  challenge: true
                  config:
                    # If true a lot of kerberos/security related debugging output will be logged to standard out
                    krb_debug: false
                    # If true then the realm will be stripped from the user name
                    strip_realm_from_principal: true
                authentication_backend:
                  type: noop
              basic_internal_auth_domain:
                description: "Authenticate via HTTP Basic against internal users database"
                http_enabled: true
                transport_enabled: true
                order: 4
                http_authenticator:
                  type: basic
                  challenge: true
                authentication_backend:
                  type: internal
              proxy_auth_domain:
                description: "Authenticate via proxy"
                http_enabled: false
                transport_enabled: false
                order: 3
                http_authenticator:
                  type: proxy
                  challenge: false
                  config:
                    user_header: "x-proxy-user"
                    roles_header: "x-proxy-roles"
                authentication_backend:
                  type: noop
              jwt_auth_domain:
                description: "Authenticate via Json Web Token"
                http_enabled: false
                transport_enabled: false
                order: 0
                http_authenticator:
                  type: jwt
                  challenge: false
                  config:
                    signing_key: "base64 encoded HMAC key or public RSA/ECDSA pem key"
                    jwt_header: "Authorization"
                    jwt_url_parameter: null
                    jwt_clock_skew_tolerance_seconds: 30
                    roles_key: null
                    subject_key: null
                authentication_backend:
                  type: noop
              clientcert_auth_domain:
                description: "Authenticate via SSL client certificates"
                http_enabled: false
                transport_enabled: false
                order: 2
                http_authenticator:
                  type: clientcert
                  config:
                    username_attribute: cn #optional, if omitted DN becomes username
                  challenge: false
                authentication_backend:
                  type: noop
              ldap:
                description: "Authenticate via LDAP or Active Directory"
                http_enabled: false
                transport_enabled: false
                order: 5
                http_authenticator:
                  type: basic
                  challenge: false
                authentication_backend:
                  # LDAP authentication backend (authenticate users against a LDAP or Active Directory)
                  type: ldap
                  config:
                    # enable ldaps
                    enable_ssl: false
                    # enable start tls, enable_ssl should be false
                    enable_start_tls: false
                    # send client certificate
                    enable_ssl_client_auth: false
                    # verify ldap hostname
                    verify_hostnames: true
                    hosts:
                    - localhost:8389
                    bind_dn: null
                    password: null
                    userbase: 'ou=people,dc=example,dc=com'
                    # Filter to search for users (currently in the whole subtree beneath userbase)
                    # {0} is substituted with the username
                    usersearch: '(sAMAccountName={0})'
                    # Use this attribute from the user as username (if not set then DN is used)
                    username_attribute: null
            authz:
              roles_from_myldap:
                description: "Authorize via LDAP or Active Directory"
                http_enabled: false
                transport_enabled: false
                authorization_backend:
                  # LDAP authorization backend (gather roles from a LDAP or Active Directory, you have to configure the above LDAP authentication backend settings too)
                  type: ldap
                  config:
                    # enable ldaps
                    enable_ssl: false
                    # enable start tls, enable_ssl should be false
                    enable_start_tls: false
                    # send client certificate
                    enable_ssl_client_auth: false
                    # verify ldap hostname
                    verify_hostnames: true
                    hosts:
                    - localhost:8389
                    bind_dn: null
                    password: null
                    rolebase: 'ou=groups,dc=example,dc=com'
                    # Filter to search for roles (currently in the whole subtree beneath rolebase)
                    # {0} is substituted with the DN of the user
                    # {1} is substituted with the username
                    # {2} is substituted with an attribute value from user's directory entry, of the authenticated user. Use userroleattribute to specify the name of the attribute
                    rolesearch: '(member={0})'
                    # Specify the name of the attribute which value should be substituted with {2} above
                    userroleattribute: null
                    # Roles as an attribute of the user entry
                    userrolename: disabled
                    #userrolename: memberOf
                    # The attribute in a role entry containing the name of that role, Default is "name".
                    # Can also be "dn" to use the full DN as rolename.
                    rolename: cn
                    # Resolve nested roles transitive (roles which are members of other roles and so on ...)
                    resolve_nested_roles: true
                    userbase: 'ou=people,dc=example,dc=com'
                    # Filter to search for users (currently in the whole subtree beneath userbase)
                    # {0} is substituted with the username
                    usersearch: '(uid={0})'
                    # Skip users matching a user name, a wildcard or a regex pattern
                    #skip_users:
                    #  - 'cn=Michael Jackson,ou*people,o=TEST'
                    #  - '/\S*/'
              roles_from_another_ldap:
                description: "Authorize via another Active Directory"
                http_enabled: false
                transport_enabled: false
                authorization_backend:
                  type: ldap
                  #config goes here ...
          #    auth_failure_listeners:
          #      ip_rate_limiting:
          #        type: ip
          #        allowed_tries: 10
          #        time_window_seconds: 3600
          #        block_expiry_seconds: 600
          #        max_blocked_clients: 100000
          #        max_tracked_clients: 100000
          #      internal_authentication_backend_limiting:
          #        type: username
          #        authentication_backend: intern
          #        allowed_tries: 10
          #        time_window_seconds: 3600
          #        block_expiry_seconds: 600
          #        max_blocked_clients: 100000
          #        max_tracked_clients: 100000
      # log4j2.properties:

    # Extra environment variables to append to this nodeGroup
    # This will be appended to the current 'env:' key. You can use any of the kubernetes env
    # syntax here
    extraEnvs:
      - name: DISABLE_INSTALL_DEMO_CONFIG
        value: "true"
      #- name: DISABLE_SECURITY_PLUGIN
      #  value: "true"
    #  - name: MY_ENVIRONMENT_VAR
    #    value: the_value_goes_here

    # Allows you to load environment variables from kubernetes secret or config map
    envFrom: []
    # - secretRef:
    #     name: env-secret
    # - configMapRef:
    #     name: config-map

    # A list of secrets and their paths to mount inside the pod
    # This is useful for mounting certificates for security and for mounting
    # the X-Pack license
    secretMounts: []

    hostAliases: []
    # - ip: "127.0.0.1"
    #   hostnames:
    #   - "foo.local"
    #   - "bar.local"

    image:
      repository: "opensearchproject/opensearch"
      # override image tag, which is .Chart.AppVersion by default
      tag: ""
      pullPolicy: "IfNotPresent"

    podAnnotations: {}
      # iam.amazonaws.com/role: es-cluster

    # OpenSearch Statefulset annotations
    openSearchAnnotations: {}

    # additionals labels
    labels: {}

    opensearchJavaOpts: "-Xmx512M -Xms512M"

    resources:
      requests:
        cpu: "800m"
        memory: "500Mi"

    initResources: {}
    #  limits:
    #     cpu: "25m"
    #     memory: "128Mi"
    #  requests:
    #     cpu: "25m"
    #     memory: "128Mi"

    sidecarResources: {}
    #   limits:
    #     cpu: "25m"
    #     memory: "128Mi"
    #   requests:
    #     cpu: "25m"
    #     memory: "128Mi"

    networkHost: "0.0.0.0"

    rbac:
      create: false
      serviceAccountAnnotations: {}
      serviceAccountName: ""

    podSecurityPolicy:
      create: false
      name: ""
      spec:
        privileged: true
        fsGroup:
          rule: RunAsAny
        runAsUser:
          rule: RunAsAny
        seLinux:
          rule: RunAsAny
        supplementalGroups:
          rule: RunAsAny
        volumes:
          - secret
          - configMap
          - persistentVolumeClaim
          - emptyDir

    persistence:
      enabled: true
      # Set to false to disable the `fsgroup-volume` initContainer that will update permissions on the persistent disk.
      enableInitChown: true
      # override image, which is busybox by default
      # image: busybox
      # override image tag, which is latest by default
      # imageTag:
      labels:
        # Add default labels for the volumeClaimTemplate of the StatefulSet
        enabled: false
      # OpenSearch Persistent Volume Storage Class
      # If defined, storageClassName: <storageClass>
      # If set to "-", storageClassName: "", which disables dynamic provisioning
      # If undefined (the default) or set to null, no storageClassName spec is
      #   set, choosing the default provisioner.  (gp2 on AWS, standard on
      #   GKE, AWS & OpenStack)
      #
      storageClass: "local-path"
      accessModes:
        - ReadWriteOnce
      size: 8Gi
      annotations: {}

    extraVolumes: []
      # - name: extras
      #   emptyDir: {}

    extraVolumeMounts: []
      # - name: extras
      #   mountPath: /usr/share/extras
      #   readOnly: true

    extraContainers: []
      # - name: do-something
      #   image: busybox
      #   command: ['do', 'something']

    extraInitContainers: []
      # - name: do-somethings
      #   image: busybox
      #   command: ['do', 'something']

    # This is the PriorityClass settings as defined in
    # https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass
    priorityClassName: ""

    # By default this will make sure two pods don't end up on the same node
    # Changing this to a region would allow you to spread pods across regions
    antiAffinityTopologyKey: "kubernetes.io/hostname"

    # Hard means that by default pods will only be scheduled if there are enough nodes for them
    # and that they will never end up on the same node. Setting this to soft will do this "best effort"
    antiAffinity: "soft"

    # This is the node affinity settings as defined in
    # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#node-affinity-beta-feature
    nodeAffinity: {}

    # This is the pod topology spread constraints
    # https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
    topologySpreadConstraints: []

    # The default is to deploy all pods serially. By setting this to parallel all pods are started at
    # the same time when bootstrapping the cluster
    podManagementPolicy: "Parallel"

    # The environment variables injected by service links are not used, but can lead to slow OpenSearch boot times when
    # there are many services in the current namespace.
    # If you experience slow pod startups you probably want to set this to `false`.
    enableServiceLinks: true

    protocol: https
    httpPort: 9200
    transportPort: 9300
    metricsPort: 9600
    httpHostPort: ""
    transportHostPort: ""


    service:
      labels: {}
      labelsHeadless: {}
      headless:
        annotations: {}
      type: ClusterIP
      # The IP family and IP families options are to set the behaviour in a dual-stack environment
      # Omitting these values will let the service fall back to whatever the CNI dictates the defaults
      # should be
      #
      # ipFamilyPolicy: SingleStack
      # ipFamilies:
      # - IPv4
      nodePort: ""
      annotations: {}
      httpPortName: http
      transportPortName: transport
      metricsPortName: metrics
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      externalTrafficPolicy: ""

    updateStrategy: RollingUpdate

    # This is the max unavailable setting for the pod disruption budget
    # The default value of 1 will make sure that kubernetes won't allow more than 1
    # of your pods to be unavailable during maintenance
    maxUnavailable: 1

    podSecurityContext:
      fsGroup: 1000
      runAsUser: 1000

    securityContext:
      capabilities:
        drop:
          - ALL
      # readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000

    securityConfig:
      enabled: true
      path: "/usr/share/opensearch/config/opensearch-security"
      actionGroupsSecret:
      configSecret:
      internalUsersSecret:
      rolesSecret:
      rolesMappingSecret:
      tenantsSecret:
      # The following option simplifies securityConfig by using a single secret and
      # specifying the config files as keys in the secret instead of creating
      # different secrets for for each config file.
      # Note that this is an alternative to the individual secret configuration
      # above and shouldn't be used if the above secrets are used.
      config:
        # There are multiple ways to define the configuration here:
        # * If you define anything under data, the chart will automatically create
        #   a secret and mount it.
        # * If you define securityConfigSecret, the chart will assume this secret is
        #   created externally and mount it.
        # * It is an error to define both data and securityConfigSecret.
        securityConfigSecret: ""
        dataComplete: true
        data: {}
          # config.yml: |-
          # internal_users.yml: |-
          # roles.yml: |-
          # roles_mapping.yml: |-
          # action_groups.yml: |-
          # tenants.yml: |-

    # How long to wait for opensearch to stop gracefully
    terminationGracePeriod: 120

    sysctlVmMaxMapCount: 262144

    startupProbe:
      tcpSocket:
        port: 9200
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      failureThreshold: 30

    livenessProbe: {}
      # periodSeconds: 20
      # timeoutSeconds: 5
      # failureThreshold: 10
      # successThreshold: 1
      # initialDelaySeconds: 10
      # tcpSocket:
      #   port: 9200

    readinessProbe:
      tcpSocket:
        port: 9200
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 3

    ## Use an alternate scheduler.
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
    ##
    schedulerName: ""

    imagePullSecrets: []
    nodeSelector: {}
    tolerations: []

    # Enabling this will publically expose your OpenSearch instance.
    # Only enable this if you have security enabled on your cluster
    ingress:
      enabled: false
      # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
      # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
      # ingressClassName: nginx

      annotations:
        kubernetes.io/ingress.class: nginx
        cert-manager.io/cluster-issuer: ca-issuer
        # kubernetes.io/tls-acme: "true"
      path: /
      hosts:
        - opensearch.systemtracker.no-ip.org
      tls: []
        # - secretName: opensearch-tls
        #   hosts:
        #     - opensearch.systemtracker.no-ip.org

    nameOverride: ""
    fullnameOverride: ""

    masterTerminationFix: false

    opensearchLifecycle: {}
      # preStop:
      #   exec:
      #     command: ["/bin/sh", "-c", "echo Hello from the preStart handler > /usr/share/message"]
      # postStart:
      #   exec:
      #     command: ["/bin/sh", "-c", "echo Hello from the postStart handler > /usr/share/message"]

    lifecycle: {}
      # preStop:
      #   exec:
      #     command: ["/bin/sh", "-c", "echo Hello from the postStart handler > /usr/share/message"]
      # postStart:
      #   exec:
      #     command:
      #       - bash
      #       - -c
      #       - |
      #         #!/bin/bash
      #         # Add a template to adjust number of shards/replicas1
      #         TEMPLATE_NAME=my_template
      #         INDEX_PATTERN="logstash-*"
      #         SHARD_COUNT=8
      #         REPLICA_COUNT=1
      #         ES_URL=http://localhost:9200
      #         while [[ "$(curl -s -o /dev/null -w '%{http_code}\n' $ES_URL)" != "200" ]]; do sleep 1; done
      #         curl -XPUT "$ES_URL/_template/$TEMPLATE_NAME" -H 'Content-Type: application/json' -d'{"index_patterns":['\""$INDEX_PATTERN"\"'],"settings":{"number_of_shards":'$SHARD_COUNT',"number_of_replicas":'$REPLICA_COUNT'}}'

    keystore: []
    # To add secrets to the keystore:
    #  - secretName: opensearch-encryption-key

    networkPolicy:
      create: false
      ## Enable creation of NetworkPolicy resources. Only Ingress traffic is filtered for now.
      ## In order for a Pod to access OpenSearch, it needs to have the following label:
      ## {{ template "uname" . }}-client: "true"
      ## Example for default configuration to access HTTP port:
      ## opensearch-master-http-client: "true"
      ## Example for default configuration to access transport port:
      ## opensearch-master-transport-client: "true"

      http:
        enabled: false

    # Deprecated
    # please use the above podSecurityContext.fsGroup instead
    fsGroup: ""

    ## Set optimal sysctl's through securityContext. This requires privilege. Can be disabled if
    ## the system has already been preconfigured. (Ex: https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html)
    ## Also see: https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/
    sysctl:
      enabled: false

    ## Set optimal sysctl's through privileged initContainer.
    sysctlInit:
      enabled: false
      # override image, which is busybox by default
      # image: busybox
      # override image tag, which is latest by default
      # imageTag:

    ## Enable to add 3rd Party / Custom plugins not offered in the default OpenSearch image.
    plugins:
      enabled: false
      installList: []
      # - example-fake-plugin

    # -- Array of extra K8s manifests to deploy
    extraObjects: []
      # - apiVersion: secrets-store.csi.x-k8s.io/v1
      #   kind: SecretProviderClass
      #   metadata:
      #     name: argocd-secrets-store
      #   spec:
      #     provider: aws
      #     parameters:
      #       objects: |
      #         - objectName: "argocd"
      #           objectType: "secretsmanager"
      #           jmesPath:
      #               - path: "client_id"
      #                 objectAlias: "client_id"
      #               - path: "client_secret"
      #                 objectAlias: "client_secret"
      #     secretObjects:
      #     - data:
      #       - key: client_id
      #         objectName: client_id
      #       - key: client_secret
      #         objectName: client_secret
      #       secretName: argocd-secrets-store
      #       type: Opaque
      #       labels:
      #         app.kubernetes.io/part-of: argocd